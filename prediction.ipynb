{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following on from the exploration done in the exploratory_analysis.ipynb notebook, I will work on the actual prediction task for the ionosphere dataset from UCI to be found here: https://archive.ics.uci.edu/ml/datasets/Ionosphere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random as rnd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix\n",
    "from sklearn.cross_validation import KFold, train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "%matplotlib inline\n",
    "rnd.seed(111)\n",
    "\n",
    "data = pd.read_csv('ionosphere_processed.csv', index_col=0)\n",
    "data.drop('1', axis=1, inplace=True)\n",
    "X = data.iloc[:, :-1].as_matrix()\n",
    "y = np.array(data.iloc[:, -1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the ionosphere dataset is a classification problem with the target variable taking on either 'good' or 'bad' values, I will start with a logistic regression and then go from there trying to improve on that performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logit_classifier = LogisticRegression(solver='liblinear')\n",
    "logit_classifier.fit(X, y)\n",
    "yhat = logit_classifier.predict(X)\n",
    "probabilities = logit_classifier.predict_proba(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'yhat' now contains the model's predictions for each observation while 'probabilities' gives each observation's probability to belong to either class. Since this is a two-class classification problem, the probabilities should in all cases sum to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilities.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decision made by the classifier is then simply to predict that an observation belongs to the class with the higher probability. In this case, that makes sense; however, there might also be other contexts in which one would like to classify a given observation as belonging to some class already if it has a probability for that class greater than e.g. a threshold of 30%. The reason might be that the costs for a false negative significantly outweigh the costs of a false positive. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at how well the classifier did in predicting the target variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 97,  29],\n",
       "       [  5, 220]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_mat_0 = confusion_matrix(y_true=y, y_pred=yhat)\n",
    "conf_mat_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top-left of the confusion matrix are true positives, top-right are false negatives, bottom-left are false positives, and bottom-right are true negatives. It seems the simple logistic regression classifier is not doing too badly; however, these performance metrics are giving too positive an impression. The reason for that is that I used the entire dataset to train the classifier and subsequently evaluated over the entire dataset, too. This can easily lead to an underestimation of prediction errors and give too 'rosy' a picture. \n",
    "\n",
    "In order to avoid this, one could for example split the dataset into two pieces using the first to train the classifier and the second to evaluate it. This can give a better impression of how well the classifier is able to generalize, i.e. predict correct labels for previously-unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.33,\n",
    "                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(235, 33)\n",
      "(116, 33)\n",
      "(235,)\n",
      "(116,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The train_test_split() function has helpfully divided the dataset into altogether four pieces: two for the features, and two for the target variable. The samples were randomly selected.\n",
    "\n",
    "Now I can train the classifier only on the train subset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logit_classifier = LogisticRegression(solver='liblinear')\n",
    "logit_classifier.fit(X_train, y_train)\n",
    "yhat = logit_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[34, 15],\n",
       "       [ 0, 67]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_mat_1 = confusion_matrix(y_true=y_test, y_pred=yhat)\n",
    "conf_mat_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does this compare to the confusion matrix from above?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90313390313390318"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(conf_mat_0[0, 0] + conf_mat_0[1, 1]) / sum(sum(conf_mat_0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87068965517241381"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(conf_mat_1[0, 0] + conf_mat_1[1, 1]) / sum(sum(conf_mat_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the fraction of correctly classified observations has gone down, demonstrating that using the entire dataset for training and testing underestimates the classification error for unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking the idea of using subsets of the dataset for training and other subsets for testing one step further leads to what is called k-fold cross-validation (https://en.wikipedia.org/wiki/Cross-validation_(statistics)#k-fold_cross-validation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In k-fold cross-validation, the dataset is divided into k equally sized parts. The classifier is then trained on k-1 of those and evaluated on the remaining part. This process is repeated k times so that each partition (or fold) is used as a test set once. The prediction error can then be averaged over all k folds in order to better estimate how the classifier would generalize. Let's try this out before moving on from logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kf = KFold(n=X.shape[0], n_folds=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_conf_mat = []\n",
    "for train_idx, test_idx in kf:\n",
    "    classifier = LogisticRegression(solver='liblinear')\n",
    "    classifier.fit(X[train_idx, :], y[train_idx])\n",
    "    yhat = classifier.predict(X[test_idx, :])\n",
    "    list_conf_mat.append(confusion_matrix(y_true=y[test_idx],\n",
    "                                          y_pred=yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18  8]\n",
      " [ 0 45]]\n",
      "\n",
      "[[14  7]\n",
      " [ 2 47]]\n",
      "\n",
      "[[16  9]\n",
      " [ 0 45]]\n",
      "\n",
      "[[16  9]\n",
      " [ 0 45]]\n",
      "\n",
      "[[16 13]\n",
      " [ 2 39]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for conf_mat in list_conf_mat: \n",
    "    print(conf_mat)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85746478873239451"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([(cm[0, 0] + cm[1, 1]) / sum(sum(cm)) for cm in list_conf_mat])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On average, the logistic regression correctly classifies about 86% of the observations as evaluated by 5-fold cross-validation. From here on out, I will try to improve on this baseline performance."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
